{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zyc/.local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_input(path, label=True):\n",
    "    df = pd.read_csv(path)\n",
    "    if label:\n",
    "        df_X = df.drop(['user_id', 'eval_set', 'product_id', 'label'], 1)\n",
    "        columns = df_X.columns\n",
    "        return df_X.astype(float).values, df['label'], df['user_id'], df['product_id'], columns\n",
    "    else:\n",
    "        return df.drop(['user_id', 'eval_set', 'product_id'], 1).astype(float).values, df['user_id'], df['product_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y, user_ids, product_ids, columns = get_input('../data/train.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "    \n",
    "def choose(probs, pNone=None):\n",
    "    max_score, j, predNone = -1, -1, False\n",
    "    for i in range(len(probs) + 1):\n",
    "        score = f1_predict(probs, i, predNone=False)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            j = i\n",
    "            predNone = False\n",
    "    for i in range(len(probs) + 1):\n",
    "        score = f1_predict(probs, i, predNone=True)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            j = i\n",
    "            predNone = True\n",
    "    return j, predNone, max_score\n",
    "\n",
    "def f1_predict(probs, k, predNone=False):\n",
    "    if k == 0 and not predNone: return 0\n",
    "    pNone = (1-probs).prod()\n",
    "    # with 1-pNone probability the true label is not \"None\"\n",
    "    p1 = probs[:k].sum() / (k+1 if predNone else k)\n",
    "    r1 = probs[:k].sum() / probs.sum()\n",
    "    f11 = 2*p1*r1/(p1+r1) if p1+r1 > 0 else 0\n",
    "    # with pNone probability the true label is \"None\"\n",
    "    p2 = (1 if predNone else 0) / (k+1 if predNone else k)\n",
    "    r2 = 1 if predNone else 0\n",
    "    f12 = 2*p2*r2/(p2+r2) if p2+r2 > 0 else 0\n",
    "    return (1-pNone)*f11 + pNone*f12\n",
    "\n",
    "def f1_score(labels, k, predNone=False):\n",
    "    if sum(labels) > 0 and k > 0:\n",
    "        p = sum(labels[:k])/(k+1 if predNone else k)\n",
    "        r = sum(labels[:k])/sum(labels)\n",
    "        if p+r > 0: return 2*p*r/(p+r)\n",
    "    if sum(labels) == 0 and predNone:\n",
    "        p = 1/(k+1)\n",
    "        r = 1\n",
    "        return 2*p*r/(p+r)\n",
    "    return 0\n",
    "\n",
    "\n",
    "def constuct_user(y, y_pred_proba, user_ids, product_ids):\n",
    "    user = defaultdict(list)\n",
    "    for y_real, y_prob, user_id, product_id in zip(y, y_pred_proba, user_ids, product_ids):\n",
    "        user[user_id].append((y_real, y_prob, product_id))\n",
    "    return user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalibratedClassifierCV(base_estimator=LGBMClassifier(boosting_type='gbdt', colsample_bytree=1, learning_rate=0.1,\n",
       "        max_bin=255, max_depth=-1, min_child_samples=10,\n",
       "        min_child_weight=5, min_split_gain=0, n_estimators=200, nthread=-1,\n",
       "        num_leaves=200, objective='binary', reg_alpha=0, reg_lambda=0,\n",
       "        seed=0, silent=True, subsample=0.95, subsample_for_bin=50000,\n",
       "        subsample_freq=5),\n",
       "            cv='prefit', method='isotonic')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_kfold = GroupKFold(n_splits=5)\n",
    "\n",
    "for train_index, val_index in group_kfold.split(X, y, user_ids.values):\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_val, y_val = X[val_index], y[val_index]\n",
    "m = LGBMClassifier(num_leaves=200, n_estimators=200, subsample=0.95, subsample_freq=5)\n",
    "m.fit(X_train, y_train)\n",
    "ccv = CalibratedClassifierCV(m, method='isotonic', cv='prefit')\n",
    "ccv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred_prob = ccv.predict_proba(X_train)[:, 1]\n",
    "y_val_pred_prob = ccv.predict_proba(X_val)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_best_products(r):\n",
    "    r.sort(key=lambda o: o[1], reverse=True)\n",
    "    labels = np.array([rr[0] for rr in r])\n",
    "    probs =  np.array([rr[1] for rr in r])\n",
    "#    probs =  np.array([rr[1] for rr in r])\n",
    "    product_ids =  np.array([rr[2] for rr in r])\n",
    "#    k, predNone, predicted_f1 = maximize_expectation(probs)\n",
    "    k, predNone, predicted_f1 = choose(probs)\n",
    "    best_products = np.append(product_ids[:k], [\"None\"]) if predNone else product_ids[:k]\n",
    "    true_f1 = f1_score(labels, k, predNone)\n",
    "    return best_products, true_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "def evaluate(y, y_pred_proba, user_ids, product_ids):\n",
    "    user = constuct_user(y, y_pred_proba, user_ids, product_ids)\n",
    "    res = 0\n",
    "    for i, (user_id, r) in enumerate(user.iteritems()):\n",
    "        print(u2o[user_id], file=f)\n",
    "        print(json.dumps(r), file=f)\n",
    "        #candidates, true_f1 = get_best_products(r)\n",
    "        #res += true_f1\n",
    "    #return (res / len(user)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "orders_train = pd.read_csv('../csv/orders.csv')\n",
    "orders_train = orders_train[orders_train.eval_set == 'train']\n",
    "o, u = orders_train['order_id'], orders_train['user_id']\n",
    "u2o = {uu: oo for oo, uu in zip(o, u)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data/my_train_record', 'w') as f:\n",
    "    evaluate(y_train, y_train_pred_prob, user_ids[train_index], product_ids[train_index])\n",
    "    evaluate(y_val, y_val_pred_prob, user_ids[val_index], product_ids[val_index])\n",
    "#print('train\\t%s' % evaluate(y_train, y_train_pred_prob, user_ids[train_index], product_ids[train_index]))\n",
    "#print('test\\t%s' % evaluate(y_val, y_val_pred_prob, user_ids[val_index], product_ids[val_index]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for k, v in zip(columns, m.feature_importances_):\n",
    "#    print(\"%s\\t%s\" % (k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28min 15s, sys: 4.33 s, total: 28min 19s\n",
      "Wall time: 3min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "m = LGBMClassifier(num_leaves=200, n_estimators=200, subsample=0.95, subsample_freq=5)\n",
    "m.fit(X, y)\n",
    "ccv = CalibratedClassifierCV(m, method='isotonic', cv='prefit')\n",
    "ccv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders_test = pd.read_csv('../csv/orders.csv')\n",
    "orders_test = orders_test[orders_test.eval_set == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o, u = orders_test['order_id'], orders_test['user_id']\n",
    "u2o = {uu: oo for oo, uu in zip(o, u)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test, user_ids_test, product_ids_test = get_input('../data/test.data', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_pred_proba = ccv.predict_proba(X_test)[:, 1]\n",
    "#y_test_pred_proba = bst.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_test = constuct_user(np.zeros(X_test.shape[0]), y_test_pred_proba, user_ids_test, product_ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/my_test_record', 'w') as f:\n",
    "    for i, (user_id, r) in enumerate(user_test.iteritems()):\n",
    "        print(u2o[user_id], file=f)\n",
    "        print(json.dumps(r), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "with open('../data/result_20170807_second_refine_features.csv', 'w') as f:\n",
    "    print('order_id,products', file=f)\n",
    "    for user_id, r in user_test.iteritems():\n",
    "        order_id = u2o[user_id]\n",
    "        v = [str(p) for p in get_best_products(r)[0]]\n",
    "        print('%s,%s' % (order_id, ' '.join(v)), file=f)\n",
    "        #if len(v) == 0:\n",
    "        #    print('%s,None' % order_id, file=f)\n",
    "        #else:\n",
    "        #    print('%s,%s' % (order_id, ' '.join(v)), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
