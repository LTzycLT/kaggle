{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading train_1.csv ...\n",
      "Index([u'Page', u'2015-07-01', u'2015-07-02', u'2015-07-03', u'2015-07-04',\n",
      "       u'2015-07-05', u'2015-07-06', u'2015-07-07', u'2015-07-08',\n",
      "       u'2015-07-09',\n",
      "       ...\n",
      "       u'2016-12-22', u'2016-12-23', u'2016-12-24', u'2016-12-25',\n",
      "       u'2016-12-26', u'2016-12-27', u'2016-12-28', u'2016-12-29',\n",
      "       u'2016-12-30', u'2016-12-31'],\n",
      "      dtype='object', length=551)\n",
      "('X', (145063, 550))\n",
      "scale data now...\n",
      "done.\n",
      "('Train size:', (137809, 550), 'Test size:', (7254, 550))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.utils.data as data_utils\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle as pkl\n",
    "\n",
    "\n",
    "USE_CUDA = False\n",
    "\n",
    "torch.manual_seed(1)  # reproducible\n",
    "if USE_CUDA: torch.cuda.set_device(1)\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "seq_len = 1\n",
    "out_size = 1\n",
    "pred_date_len = 60\n",
    "\n",
    "#Importing dataset\n",
    "if os.path.exists('../data/train_1.hdf'):\n",
    "    pass\n",
    "else:\n",
    "    print('reading train_1.csv ...')\n",
    "    train = pd.read_csv('../csv/train_1.csv').fillna(0) #145063*551\n",
    "    print(train.columns)\n",
    "    page = train['Page']\n",
    "    train.head()\n",
    "    #Dropping Page Column\n",
    "    X = train.drop('Page',axis = 1)\n",
    "    Y = X['2016-12-31'].values\n",
    "    X = X.values\n",
    "    shape = X.shape\n",
    "    print(\"X\",shape)\n",
    "\n",
    "print('scale data now...')\n",
    "sc = MinMaxScaler()\n",
    "X = np.reshape(sc.fit_transform(np.reshape(X,(-1,1))), shape)\n",
    "Y = np.reshape(sc.fit_transform(np.reshape(Y,(-1,1))), -1)\n",
    "print('done.')\n",
    "\n",
    "\n",
    "#trian and test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.05)\n",
    "print('Train size:',X_train.shape,'Test size:',X_test.shape)\n",
    "\n",
    "trainDB=data_utils.TensorDataset(torch.from_numpy(X_train).float().unsqueeze(2),\\\n",
    "                                torch.from_numpy(Y_train).float().unsqueeze(1))\n",
    "trainloader=data_utils.DataLoader(trainDB,batch_size=batch_size,shuffle=True)\n",
    "testDB=data_utils.TensorDataset(torch.from_numpy(X_test).float().unsqueeze(2),\\\n",
    "                                torch.from_numpy(Y_test).float().unsqueeze(1))\n",
    "testloader=data_utils.DataLoader(testDB,batch_size=batch_size,shuffle=True)\n",
    "testdataiter=iter(testloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict():\n",
    "    rnn = torch.load('rnn.mdl')\n",
    "    h_state = pkl.load(open('h_state','rb'))\n",
    "\n",
    "    trainDB = data_utils.TensorDataset(torch.from_numpy(X).float().unsqueeze(2), \\\n",
    "                                       torch.from_numpy(Y).float().unsqueeze(1))\n",
    "    trainloader = data_utils.DataLoader(trainDB, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    dataiter = iter(trainloader)\n",
    "    x_all, _ = dataiter.next()\n",
    "    y_all = torch.FloatTensor()\n",
    "    if USE_CUDA: y_all = y_all.cuda()\n",
    "    while x_all.size(0) == batch_size:\n",
    "        x = Variable(x_all)\n",
    "        if USE_CUDA: x = x.cuda()\n",
    "\n",
    "        prediction, h_state = rnn(x, h_state)  # rnn output\n",
    "        h_state = Variable(h_state.data)\n",
    "        y_all = torch.cat((y_all,prediction.data),dim=0)\n",
    "        x_all, _ = dataiter.next()\n",
    "    print('last x_all size:',x_all.size())\n",
    "\n",
    "    x = Variable(torch.cat( (x_all, torch.zeros((batch_size-x_all.size(0),x_all.size(1),1)) )\n",
    "                   ,dim=0)\n",
    "                 )\n",
    "    if USE_CUDA: x = x.cuda()\n",
    "    prediction, h_state = rnn(x, h_state)  # rnn output\n",
    "    h_state = Variable(h_state.data)\n",
    "    y_all = torch.cat((y_all,prediction.data[:x_all.size(0)]),dim=0)\n",
    "    y_all = torch.squeeze(y_all,dim=1).cpu().numpy()\n",
    "    print('sc before:',y_all)\n",
    "    y_all = sc.inverse_transform(y_all)\n",
    "    print('total y_all size:',len(y_all))\n",
    "    print('sc after:',y_all)\n",
    "\n",
    "    return y_all\n",
    "\n",
    "\n",
    "def submit(y_all):\n",
    "    key_1 = pd.read_csv('../csv/key_1.csv')\n",
    "    ss_1 = pd.read_csv('../csv/sample_submission_1.csv')\n",
    "\n",
    "    sub = pd.read_csv(\"../csv/key_1.csv\", converters={'Page': lambda p: p[:-11]}, index_col='Page')\\\n",
    "        .join(pd.Series(y_all).to_frame(name='Visits'), how='left').fillna(0)\n",
    "    print(sub)\n",
    "    sub.to_csv('sub.csv', float_format='%.0f', index=False)\n",
    "    return\n",
    "\n",
    "    ids = key_1.Id.values\n",
    "    pages = key_1.Page.values\n",
    "\n",
    "    d_pages = {}\n",
    "    for id, page in zip(ids, pages):\n",
    "        d_pages[id] = page[:-11]\n",
    "\n",
    "    d_visits = {}\n",
    "    for page, visits_number in zip(pages, y_all):\n",
    "        d_visits[page] = visits_number\n",
    "    print(len(d_visits))\n",
    "\n",
    "    print('Modifying sample submission...')\n",
    "    ss_ids = ss_1.Id.values\n",
    "    ss_visits = ss_1.Visits.values\n",
    "\n",
    "    for i, ss_id in enumerate(ss_ids):\n",
    "        try:\n",
    "            ss_visits[i] = d_visits[d_pages[ss_id]]\n",
    "        except KeyError as err:\n",
    "            print('err:',i,ss_id)\n",
    "            return\n",
    "\n",
    "    print('Saving submission...')\n",
    "    subm = pd.DataFrame({'Id': ss_ids, 'Visits': ss_visits})\n",
    "    subm.to_csv('../sub/submission.csv', index=False)\n",
    "    print('done.')\n",
    "\n",
    "def evaluate(rnn, h_state):\n",
    "    total_error=0\n",
    "    dataiter = iter(testloader)\n",
    "    x_all, _ = dataiter.next()\n",
    "    counter = 0\n",
    "    loss_func = nn.MSELoss()\n",
    "    while x_all.size(0) == batch_size:\n",
    "        pos = np.random.randint(pred_date_len, x_all.size(1) - pred_date_len)\n",
    "        # print('pos:',pos,x_all.size())\n",
    "        x = Variable(x_all[:, :pos, :])\n",
    "        y = Variable(x_all[:, pos:pos + pred_date_len, :])\n",
    "        if USE_CUDA:\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        y = y.view(batch_size, pred_date_len)\n",
    "        y = y.sum(dim=1)\n",
    "        # print(x, y)\n",
    "\n",
    "        prediction,_ = rnn.forward(x,h_state)\n",
    "        error = loss_func(prediction, y)\n",
    "        total_error += error.data[0]\n",
    "\n",
    "        x_all, _ = dataiter.next()\n",
    "        counter+=1\n",
    "    print('total error:',total_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_units = 128\n",
    "        self.model = nn.Sequential()\n",
    "        self.num_layers = 2\n",
    "\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=seq_len,\n",
    "            hidden_size=self.hidden_units,  # rnn hidden unit\n",
    "            num_layers=self.num_layers,  # number of rnn layer\n",
    "            batch_first=True, # input & output will has batch size as 1st dimension. e.g. (batch, time_step, input_size)\n",
    "            nonlinearity='relu',\n",
    "            dropout=0.2\n",
    "        )\n",
    "        self.out = nn.Linear(self.hidden_units, 1)\n",
    "\n",
    "    def forward(self, x, h_state):\n",
    "        # x (batch, time_step, input_size)\n",
    "        # h_state (n_layers, batch, hidden_size)\n",
    "        # r_out (batch, time_step, hidden_size)\n",
    "        r_out, h_state = self.rnn(x, h_state)\n",
    "\n",
    "        outs = []  # save all predictions\n",
    "        for time_step in range(r_out.size(1)):  # calculate output for each time step\n",
    "            outs.append(self.out(r_out[:, time_step, :]))\n",
    "        return torch.stack(outs, dim=1)[:,-1,:], h_state\n",
    "        \n",
    "        #return self.out(r_out.stack(v, 1).view(x.size()[0]), -1), h_state\n",
    "\n",
    "        # instead, for simplicity, you can replace above codes by follows\n",
    "        # r_out = r_out.view(-1, 32)\n",
    "        # outs = self.out(r_out)\n",
    "        # return outs, h_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    rnn = RNN()\n",
    "    if USE_CUDA: rnn = rnn.cuda()\n",
    "    print(rnn)\n",
    "    optimizer = torch.optim.Adam(rnn.parameters(), lr=1e-3)   # optimize all cnn parameters\n",
    "    loss_func = nn.MSELoss()\n",
    "    h_state = None      # for initial hidden state\n",
    "\n",
    "    dataiter=iter(trainloader)\n",
    "    for step in range(200):\n",
    "        x_all, _ = dataiter.next()\n",
    "        if x_all.size(0)<batch_size:\n",
    "            dataiter = iter(trainloader)\n",
    "            x_all, _ = dataiter.next()\n",
    "        pos=np.random.randint(pred_date_len,x_all.size(1)-pred_date_len)\n",
    "        print 'pos:',pos,x_all.size()\n",
    "        x=Variable(x_all[:,:pos,:])\n",
    "        y=Variable(x_all[:,pos:pos+pred_date_len,:])\n",
    "        if USE_CUDA:\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        \n",
    "        y=y.contiguous().view(batch_size,pred_date_len)\n",
    "        y=y.sum(dim=1)\n",
    "        # print(x, y)\n",
    "\n",
    "        prediction, h_state = rnn(x, h_state)   # rnn output\n",
    "        # !! next step is important !!\n",
    "        h_state = Variable(h_state.data)        # repack the hidden state, break the connection from last iteration\n",
    "\n",
    "        loss = loss_func(prediction, y)         # cross entropy loss\n",
    "        optimizer.zero_grad()                   # clear gradients for this training step\n",
    "        loss.backward()                         # backpropagation, compute gradients\n",
    "        print(step,loss.data[0])\n",
    "        optimizer.step()                        # apply gradients\n",
    "        \n",
    "        \n",
    "        # if step%10==0:\n",
    "        #     evaluate(rnn,h_state)\n",
    "\n",
    "    torch.save(rnn,'rnn.mdl')\n",
    "    pkl.dump(h_state,open('h_state','wb'))\n",
    "    print('saved rnn.mdl and h_state.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN (\n",
      "  (model): Sequential (\n",
      "  )\n",
      "  (rnn): RNN(1, 128, num_layers=2, batch_first=True, dropout=0.2)\n",
      "  (out): Linear (128 -> 1)\n",
      ")\n",
      "pos: 183 torch.Size([10, 550, 1])\n",
      "(0, 0.0006529833190143108)\n",
      "pos: 202 torch.Size([10, 550, 1])\n",
      "(1, 0.000429788779001683)\n",
      "pos: 309 torch.Size([10, 550, 1])\n",
      "(2, 0.000514004728756845)\n",
      "pos: 341 torch.Size([10, 550, 1])\n",
      "(3, 8.502881246386096e-05)\n",
      "pos: 322 torch.Size([10, 550, 1])\n",
      "(4, 4.411649933899753e-05)\n",
      "pos: 132 torch.Size([10, 550, 1])\n",
      "(5, 0.00028538177139125764)\n",
      "pos: 310 torch.Size([10, 550, 1])\n",
      "(6, 0.0003012921952176839)\n",
      "pos: 345 torch.Size([10, 550, 1])\n",
      "(7, 0.00018296089547220618)\n",
      "pos: 371 torch.Size([10, 550, 1])\n",
      "(8, 5.406661148299463e-05)\n",
      "pos: 351 torch.Size([10, 550, 1])\n",
      "(9, 2.5905323127517477e-05)\n",
      "pos: 203 torch.Size([10, 550, 1])\n",
      "(10, 0.0001308721984969452)\n",
      "pos: 324 torch.Size([10, 550, 1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2b1e119e7846>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#submit(y_all)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#uncomment the following code to train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-940c9e3d9117>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# cross entropy loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                   \u001b[0;31m# clear gradients for this training step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                         \u001b[0;31m# backpropagation, compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                        \u001b[0;31m# apply gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zyc/anaconda2/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zyc/anaconda2/lib/python2.7/site-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    #uncommnet the following code to predict\n",
    "    #y_all = predict()\n",
    "    #submit(y_all)\n",
    "    #uncomment the following code to train\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = torch.FloatTensor([[[1, 2], [3, 4], [5, 6]], [[7, 8], [9, 10], [11, 12]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "   1   2\n",
       "   7   8\n",
       "\n",
       "(1 ,.,.) = \n",
       "   3   4\n",
       "   9  10\n",
       "\n",
       "(2 ,.,.) = \n",
       "   5   6\n",
       "  11  12\n",
       "[torch.FloatTensor of size 3x2x2]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(v, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "   1   2\n",
       "   3   4\n",
       "   5   6\n",
       "\n",
       "(1 ,.,.) = \n",
       "   7   8\n",
       "   9  10\n",
       "  11  12\n",
       "[torch.FloatTensor of size 2x3x2]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
